{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecc1c41",
   "metadata": {},
   "source": [
    "# notebook to interpolated NEMO output on ISMIP6 grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82cb20",
   "metadata": {},
   "source": [
    "## load module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "# eos\n",
    "import gsw\n",
    "\n",
    "# data\n",
    "import netCDF4 as nc                             # read netcdf\n",
    "import xarray as xr                              # write netcdf\n",
    "import pyproj                                    # projection\n",
    "\n",
    "# plot\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# interpolation\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import LinearNDInterpolator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f4846",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696a381",
   "metadata": {},
   "source": [
    "### function to test file presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfile(cfl):\n",
    "    \"\"\"\n",
    "    Purpose: test if all the file in the input file list exist\n",
    "    \n",
    "    Args:\n",
    "        cfl: list of input file name (string)\n",
    "        \n",
    "    Return: None\n",
    "    \n",
    "    Raise:\n",
    "        FileError: file is missing\n",
    "    \"\"\"\n",
    "\n",
    "    nerr=0\n",
    "    cferr=''\n",
    "    for cfile in cfl:\n",
    "        if not os.path.isfile(cfile):\n",
    "            print (\"File {} does not exist\".format(cfile))\n",
    "            cferr=cferr+' '+cfile\n",
    "            nerr=nerr+1\n",
    "    \n",
    "    if nerr > 0:\n",
    "        raise RuntimeError('At least one file is missing '+cferr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f2578",
   "metadata": {},
   "source": [
    "### function to interpolate data and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_data(xsrc,ysrc,datasrc,masksrc,xtrg,ytrg):\n",
    "    \"\"\"\n",
    "    Purpose: interpolate datasrc and masksrc on trg grid\n",
    "    \n",
    "    Args:\n",
    "        xsrc   : X coordinates of the source grid [flatten array]\n",
    "        ysrc   : Y coordinates of the source grid [flatten array]\n",
    "        datasrc: data to interpolate on the source grid [flatten array]\n",
    "        \n",
    "        xtrg : X coordinates of the trg grid [2d array]\n",
    "        ytrg : Y coordinates of the trg grid [2d array]\n",
    "        \n",
    "    Return: \n",
    "        datatrg : datasrc interpolated on the trg grid\n",
    "        masktrg : masksrc interpolated on the trg grid\n",
    "    \"\"\"\n",
    "    \n",
    "    print('    interpolate data and mask ...')\n",
    "    \n",
    "    # interpolation of  data\n",
    "    datatrg = griddata((xsrc,ysrc), datasrc, (xtrg, ytrg), method='linear')\n",
    "    \n",
    "    # interpolation of mask\n",
    "    masktrg = griddata((xsrc,ysrc), masksrc, (xtrg, ytrg), method='nearest')\n",
    "    \n",
    "    # mask interpolated data\n",
    "    datatrg[masktrg<1.0]=np.nan\n",
    "    \n",
    "    return datatrg, masktrg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865b9f4",
   "metadata": {},
   "source": [
    "### function to extrapolate by 1 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolation_data(data):\n",
    "    \"\"\"\n",
    "    Purpose: extrapolate by one cell the data (use the nan mean over the 8 boundary cells)\n",
    "    \n",
    "    Args:\n",
    "        data: data to interpolate on the source grid [2d array]\n",
    "        \n",
    "    Return: \n",
    "        data_ext : data extrapolated by 1 cell [2d array]\n",
    "    \"\"\"\n",
    "    \n",
    "    print('    extrapolate by 1 cell ...')\n",
    "    \n",
    "    data_ext=copy.deepcopy(data)\n",
    "    \n",
    "    # find all masked data\n",
    "    idx=np.where(np.isnan(data))\n",
    "    \n",
    "    # fill masked data if they have at least one valid value around\n",
    "    ndata=len(idx[0])\n",
    "    for iidx in range(ndata):\n",
    "        ii=idx[0][iidx]\n",
    "        jj=idx[1][iidx]\n",
    "        data_ext[ii,jj]=np.nanmean(data[ii-1:ii+2,jj-1:jj+2])\n",
    "        \n",
    "    return data_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dcc4b5",
   "metadata": {},
   "source": [
    "### function to convert CT and SA to pt0 et practical salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_TEOS10_to_EOS80(ct,sa,z,lon,lat):\n",
    "    \"\"\"\n",
    "    Purpose: convert conservative temperature and absolute salinity to potential temperature and practical salinity\n",
    "    \n",
    "    Args:\n",
    "        ct  : conservative temperature array [2D or 3D array]\n",
    "        sa  : absolute salinity array [same dimension as ct]\n",
    "        z   : depth array [same dimention as ct]\n",
    "        lon : longitude array\n",
    "        lat : latitude array\n",
    "         \n",
    "    Return: \n",
    "        sp  : practical salinity unit\n",
    "        pt0 : potential temperature reference to surface\n",
    "    \"\"\"\n",
    "    sp =gsw.conversions.SP_from_SA(sa,z,lon,lat)\n",
    "    pt0=gsw.conversions.pt_from_CT(sa,ct)\n",
    "    return sp,pt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_interpolation(data3din,zin,zout, jkout):\n",
    "    \"\"\"\n",
    "    Purpose: compute conservative vertical interpolation (bottom and top value use persistence)\n",
    "    \n",
    "    Args:\n",
    "        data3din : 3d array on src vertical discretisation\n",
    "        zin      : 1d array of src vertical level\n",
    "        zout     : 1d array of trg vertical level\n",
    "        jkout    : vertical level to proceed on output grid\n",
    "         \n",
    "    Return: \n",
    "        data2d   : data interpolated on jk output level\n",
    "    \"\"\"  \n",
    "    \n",
    "    print('    vertical interpolation ...')\n",
    "    \n",
    "    nkin, njin, niin=data3din.shape\n",
    "    \n",
    "    data3din_ext = copy.deepcopy(data3din)\n",
    "    ztmp=np.zeros(shape=(nkin,))\n",
    "    zweight=np.zeros(shape=(nkin,njin,niin))\n",
    "    zdata=np.zeros(shape=(njin,niin))\n",
    "\n",
    "    # find all w level in a ISMIP6 level\n",
    "    jkmin=np.where(zin <= zout[jkout])[0].tolist()[-1]\n",
    "    jkmax=np.where(zin >= zout[jkout+1])[0].tolist()[0] - 1\n",
    "    \n",
    "    # get list level for up and bottom\n",
    "    jkin=[*range(jkmin,jkmax+1)]\n",
    "    jkinp1=[*range(jkmin+1,jkmax+2)]\n",
    "\n",
    "    # extrapolation top data (by 1 cell) : persistence method\n",
    "    for jk in reversed(jkin):\n",
    "        zref = data3din[jk+1,:,:]\n",
    "        zdata[:,:] = data3din[jk,:,:]\n",
    "        zdata[np.isnan(zdata)] = zref[np.isnan(zdata)]\n",
    "        data3din_ext[jk,:,:] = zdata[:,:]\n",
    "\n",
    "    # extrapolation bottom data (by 1 cell) : persistence method\n",
    "    for jk in jkin:\n",
    "        zref = data3din_ext[jk-1,:,:]\n",
    "        zdata[:,:] = data3din_ext[jk,:,:]\n",
    "        zdata[np.isnan(zdata)] = zref[np.isnan(zdata)]\n",
    "        data3din_ext[jk,:,:] = zdata[:,:]\n",
    "\n",
    "    # mask data3din_ext\n",
    "    data3din_ext=np.ma.masked_invalid(data3din_ext)\n",
    "\n",
    "    # define depth of top and bottom boundary (take care of partially included)\n",
    "    zup = zin[jkin]  ; zup[0]   = zout[jkout]\n",
    "    zbot= zin[jkinp1]; zbot[-1] = zout[jkout+1]\n",
    "\n",
    "    # now we can compute weight\n",
    "    ztmp[jkin] = (zbot - zup) / (zout[jkout+1] - zout[jkout])\n",
    "    zweight[:,:,:]=ztmp[:,None,None]    \n",
    "\n",
    "    # compute mean value\n",
    "    zdata = np.ma.average(data3din_ext,weights=zweight,axis=0)\n",
    "\n",
    "    # mask data out\n",
    "    mask2dout = np.ones(shape=(njin,niin))\n",
    "    zweight[np.isnan(data3din)]=0.\n",
    "    mask2dout[np.sum(zweight,axis=0)<0.5] = np.nan         # mask 0.0 (some variable in the netcdf are not masked properly)\n",
    "    \n",
    "    # the end\n",
    "    return zdata.data[:,:] * mask2dout[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tplin):\n",
    "    \"\"\"\n",
    "    Purpose: process all the data (vertical interpolation if needed, then horizontal interpolation)\n",
    "    \n",
    "    Args:\n",
    "        tplin : tuple containing the variable dictionary [0], and the grid tuple data [1]\n",
    "        grid tuple : tuple containing (xin[1d],yin[1d],zin[1d],xout[2d],yout[2d],zout[1d],sy[slice on y (input)],sz[slice on z (input)])\n",
    "         \n",
    "    Return: \n",
    "        da    : data interpolated on output grid in a xr.dataarray\n",
    "    \"\"\"\n",
    "    \n",
    "    # set input data (need to do this this way to use dask bag map)\n",
    "    # variable dictionary\n",
    "    dvar=tplin[0]\n",
    "    \n",
    "    # grid data\n",
    "    xin,yin,zin,x2dout,y2dout,zout,sy,sz = tplin[1]\n",
    "    \n",
    "    print('process '+dvar['NEMOvar']+' ...')\n",
    "\n",
    "    print('    read data ...')\n",
    "    \n",
    "    cf_data_in=dvar['NEMOfile']\n",
    "    isfile([cf_data_in])\n",
    "    ncid= nc.Dataset(cf_data_in,'r')\n",
    "\n",
    "    # define variables name\n",
    "    cvarin = dvar['NEMOvar']\n",
    "    cvarout= dvar['ISMIP6var']\n",
    "    \n",
    "    # get n dimension\n",
    "    shape = dvar['shape']\n",
    "    \n",
    "    # read data\n",
    "    if shape == '2D':\n",
    "        data2din = ncid.variables[cvarin][0,sy,:].squeeze().filled(np.nan)\n",
    "    elif shape == '3D':\n",
    "        data3din = ncid.variables[cvarin][0,sz,sy,:].squeeze().filled(np.nan)\n",
    "    else:\n",
    "        print('ERROR: shape unknown')\n",
    "        raise\n",
    "        \n",
    "    # close file\n",
    "    ncid.close()\n",
    "    \n",
    "    if shape == '2D':\n",
    "        # define mask\n",
    "        mask2din = np.ones(shape=data2din.shape)\n",
    "        mask2din[data2din==0.0] = 0         # mask 0.0 (some variable in the netcdf are not masked properly)\n",
    "        mask2din[np.isnan(data2din)] = 0    # mask nan (ie missing value data)\n",
    "        maskin = mask2din.flatten()\n",
    "\n",
    "        # extrapolate data\n",
    "        datain = extrapolation_data(data2din).flatten()\n",
    "\n",
    "        # interpolate data and mask\n",
    "        dataout, maskout = interpolate_data(xin,yin,datain.flatten(),maskin.flatten(),x2dout,y2dout)\n",
    "        \n",
    "    elif shape == '3D':\n",
    "\n",
    "        data2din=np.zeros(shape=data3din[0,:,:].shape)\n",
    "        dataout=np.zeros(shape=(zout.shape[0]-1,x2dout.shape[0],x2dout.shape[1]))\n",
    "        maskout=np.zeros(shape=(zout.shape[0]-1,x2dout.shape[0],x2dout.shape[1]))\n",
    "        for jk in range(len(zout)-1):\n",
    "            \n",
    "            print(jk,'/',len(zout)-2)\n",
    "            \n",
    "            # vertical interpolation\n",
    "            data2din=vertical_interpolation(data3din,zin,zout,jk)\n",
    "            \n",
    "            # define mask\n",
    "            mask2din = np.ones(shape=data2din.shape)\n",
    "            mask2din[data2din==0.0] = 0         # mask 0.0 (some variable in the netcdf are not masked properly)\n",
    "            mask2din[np.isnan(data2din)] = 0    # mask nan (ie missing value data)\n",
    "            maskin = mask2din.flatten()\n",
    "\n",
    "            # extrapolate data\n",
    "            datain = extrapolation_data(data2din).flatten()\n",
    "\n",
    "            # interpolate data and mask\n",
    "            dataout[jk,:,:], maskout[jk,:,:] = interpolate_data(xin,yin,datain.flatten(),maskin.flatten(),x2dout,y2dout)\n",
    "\n",
    "    # define new attributes\n",
    "    dvar['att']['valid_min'] = np.nanmin(dataout)\n",
    "    dvar['att']['valid_max'] = np.nanmax(dataout)\n",
    "\n",
    "    # define dataarray\n",
    "    da = xr.DataArray(\n",
    "            data   = np.ma.masked_invalid(dataout),\n",
    "            dims   = dvar['dims'],\n",
    "            attrs  = dvar['att'],\n",
    "        )\n",
    "\n",
    "    return (da, cvarout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36f542",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb40da",
   "metadata": {},
   "source": [
    "### define input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5699ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do you want to use dask (3 cores it works well on my Mac)\n",
    "luse_dask=True\n",
    "\n",
    "# NEMO coordinates file\n",
    "cf_coord_NEMO='eORCA025.L121-OPM021_mesh_mask.nc'\n",
    "\n",
    "# ISMIP6 coordinates file\n",
    "cf_coord_ISMIP6='ISMIP6_ocean_grid.nc'\n",
    "\n",
    "# projection definition\n",
    "cprojNEMO='epsg:4326'\n",
    "cprojISMIP6='epsg:3031'\n",
    "\n",
    "ctag='y2029.10y'\n",
    "cconfcase='eORCA025.L121-OPM021'\n",
    "\n",
    "# output file\n",
    "cf_out='ISMIP6_{}_{}_WP1_TiPACCs.nc'.format(cconfcase,ctag)\n",
    "\n",
    "# global attributes\n",
    "dgatt = {'source' :'{} NEMO simulation'.format(cconfcase),\n",
    "         'model time' : '10 years average starting 01/01/2029',\n",
    "         'grid'   : 'ISMIP6',\n",
    "         'contact':'P. Mathiot (IGE)',\n",
    "         'creation date':'{}'.format(datetime.now()),\n",
    "        }\n",
    "\n",
    "# dict. of data for each variable\n",
    "dthetao={\n",
    "    'NEMOvar'   : 'votemper',\n",
    "    'NEMOfile'  : '{}_{}_gridT.nc'.format(cconfcase,ctag),\n",
    "    'ISMIP6var' : 'thetao',\n",
    "    'shape'     : '3D',\n",
    "    'dims'      : ['z','y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"Sea water potential temperature\",\n",
    "          units=\"°C\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ), \n",
    "     }\n",
    "\n",
    "dso={\n",
    "    'NEMOvar'   : 'vosaline',\n",
    "    'NEMOfile'  : '{}_{}_gridT.nc'.format(cconfcase,ctag),\n",
    "    'ISMIP6var' : 'so',\n",
    "    'shape'     : '3D',\n",
    "    'dims'      : ['z','y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"Sea water salinity\",\n",
    "          units=\"g/kg\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ), \n",
    "     }\n",
    "\n",
    "dsbt={\n",
    "    'NEMOvar'   : 'sosbt',\n",
    "    'NEMOfile'  : '{}_{}_gridT.nc'.format(cconfcase,ctag),\n",
    "    'ISMIP6var' : 'tob',\n",
    "    'shape'     : '2D',\n",
    "    'dims'      : ['y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"Sea water potential temperature\",\n",
    "          units=\"°C\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ), \n",
    "     }\n",
    "\n",
    "dsbs={\n",
    "    'NEMOvar'   : 'sosbs',\n",
    "    'NEMOfile'  : '{}_{}_gridT.nc'.format(cconfcase,ctag),\n",
    "    'ISMIP6var' : 'sob',\n",
    "    'shape'     : '2D',\n",
    "    'dims'      : ['y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"Sea water salinity at sea floor\",\n",
    "          units=\"g/kg\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ), \n",
    "     }\n",
    "\n",
    "dfwf={\n",
    "    'NEMOvar'   : 'sowflisf_cav',\n",
    "    'NEMOfile'  : '{}_{}_flxT.nc'.format(cconfcase,ctag),\n",
    "    'ISMIP6var' : 'ficeshelf',\n",
    "    'shape'     : '2D',\n",
    "    'dims'      : ['y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"ice-shelf melt rates\",\n",
    "          units=\"kg/m2/s\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ),\n",
    "     }\n",
    "\n",
    "disfd={\n",
    "    'NEMOvar'   : 'isfdraft',\n",
    "    'NEMOfile'  : '{}_mesh_mask.nc'.format(cconfcase),\n",
    "    'ISMIP6var' : 'depfli',\n",
    "    'shape'     : '2D',\n",
    "    'dims'      : ['y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"Depth of floating ice base below geoid\",\n",
    "          units=\"m\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ), \n",
    "     }\n",
    "\n",
    "dbathy={\n",
    "    'NEMOvar'   : 'bathy_metry',\n",
    "    'NEMOfile'  : '{}_mesh_mask.nc'.format(cconfcase),\n",
    "    'ISMIP6var' : 'deptho',\n",
    "    'shape'     : '2D',\n",
    "    'dims'      : ['y','x'],\n",
    "    'att' : dict(\n",
    "          long_name=\"Sea floor depth below geoid\",\n",
    "          units=\"m\",\n",
    "          _FillValue=-9999.99,\n",
    "          grid_mapping='crs',\n",
    "     ), \n",
    "     }\n",
    "\n",
    "\n",
    "dprj={\n",
    "    'att' : dict(\n",
    "          grid_mapping_name='polar_stereographic',\n",
    "          latitude_of_projection_origin=-90.0,\n",
    "          standard_parallel=-71.0,\n",
    "          false_easting=0.0,\n",
    "          false_northing=0.0,\n",
    "          epsg_code='epsg:3031',\n",
    "            )\n",
    "    }\n",
    "    \n",
    "ddat_lst=[dthetao,dso,dsbt,dsbs,dfwf,disfd,dbathy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31302bc",
   "metadata": {},
   "source": [
    "### load ISMIP6 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fb914",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load ISMIP6 coordinates ...')\n",
    "\n",
    "isfile([cf_coord_ISMIP6])\n",
    "ncid= nc.Dataset(cf_coord_ISMIP6,'r')\n",
    "\n",
    "xISMIP6 = ncid.variables['x'][:].squeeze()\n",
    "yISMIP6 = ncid.variables['y'][:].squeeze()\n",
    "x2dISMIP6, y2dISMIP6 = np.meshgrid(xISMIP6,yISMIP6)\n",
    "\n",
    "zbISMIP6 = ncid.variables['z_bnds'][:].squeeze()\n",
    "zISMIP6 = -np.append(zbISMIP6[:,0],zbISMIP6[:,-1][-1])\n",
    "\n",
    "lonISMIP6 = ncid.variables['longitude'][:,:].squeeze()\n",
    "latISMIP6 = ncid.variables['latitude'][:,:].squeeze()\n",
    "\n",
    "# ISMIP6 is a south stereographic grid =. there is a lat max\n",
    "latmaxISMIP6 = latISMIP6.max()\n",
    "\n",
    "ncid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95267b65",
   "metadata": {},
   "source": [
    "### create output file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703004fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start creating output dataset\n",
    "ds=xr.open_dataset(cf_coord_ISMIP6).set_coords(['longitude','latitude'])\n",
    "xcoord=ds['x']\n",
    "xcoord.attrs = dict(\n",
    "            long_name=\"x coordinate of projection\",\n",
    "            standard_name=\"projection_x_coordinate\",\n",
    "            axis='X',\n",
    "            )\n",
    "\n",
    "ycoord=ds['y']\n",
    "ycoord.attrs = dict(\n",
    "            long_name=\"y coordinate of projection\",\n",
    "            standard_name=\"projection_y_coordinate\",\n",
    "            axis='Y',\n",
    "            )\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2eefe",
   "metadata": {},
   "source": [
    "### load NEMO coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load NEMO coordinate ...')\n",
    "\n",
    "isfile([cf_coord_NEMO])\n",
    "ncid= nc.Dataset(cf_coord_NEMO,'r')\n",
    "rlatNEMO = ncid.variables['gphit'][:,:].squeeze()\n",
    "\n",
    "# get max y to avoid processing data too far away from ISMIP6 area\n",
    "imax=np.max(np.where(rlatNEMO < latmaxISMIP6)[0])\n",
    "syNEMO=slice(0,imax+1)\n",
    "print('    only load data for j between 0 and '+str(imax))\n",
    "\n",
    "# extract data\n",
    "rlatNEMO = ncid.variables['gphit'][0,syNEMO,:].squeeze()\n",
    "rlonNEMO = ncid.variables['glamt'][0,syNEMO,:].squeeze()\n",
    "\n",
    "# extract bathy and isf draft to compute ISMIP6 mbathy and misfd\n",
    "rbathyNEMO = ncid.variables['bathy_metry'][0,syNEMO,:].squeeze()\n",
    "risfdNEMO = ncid.variables['isfdraft'][0,syNEMO,:].squeeze()\n",
    "mbathyNEMO = ncid.variables['mbathy'][0,syNEMO,:].squeeze()\n",
    "misfdNEMO = ncid.variables['misf'][0,syNEMO,:].squeeze()\n",
    "\n",
    "# get max z to avoid processing data too far away from ISMIP6 area\n",
    "rdepwNEMO = ncid.variables['gdepw_1d'][0,:].squeeze()\n",
    "kmax=np.min(np.where(rdepwNEMO > zISMIP6[-1]))\n",
    "szNEMO=slice(0,kmax+1)\n",
    "\n",
    "# extract gdepw\n",
    "print('    only load data for k between 0 and '+str(kmax))\n",
    "rdepwNEMO = ncid.variables['gdepw_1d'][0,szNEMO].squeeze()\n",
    "rdeptNEMO = ncid.variables['gdept_1d'][0,szNEMO].squeeze()\n",
    "\n",
    "# close file\n",
    "ncid.close()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ea0b2",
   "metadata": {},
   "source": [
    "### convert NEMO coordinates to stereographic coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('convert NEMO {} coordinates to {} coordinates ...'.format(cprojNEMO,cprojISMIP6))\n",
    "transformer_lltoxy=pyproj.Transformer.from_crs(cprojNEMO,cprojISMIP6,always_xy=True)\n",
    "x2dNEMO,y2dNEMO = transformer_lltoxy.transform(rlonNEMO,rlatNEMO)\n",
    "xNEMO=x2dNEMO.flatten()\n",
    "yNEMO=y2dNEMO.flatten()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b710a",
   "metadata": {},
   "source": [
    "## Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3fcbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid definition (input and output) gather in the same object\n",
    "grid_data=(xNEMO,yNEMO,rdepwNEMO,x2dISMIP6,y2dISMIP6,zISMIP6,syNEMO,szNEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa626b56",
   "metadata": {},
   "source": [
    "### define list of work to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bf683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build process_data input tuple\n",
    "dat_lst=[]\n",
    "for dvar in ddat_lst:\n",
    "    dat_lst.append((dvar,grid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9686066",
   "metadata": {},
   "source": [
    "### start processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f997640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dask is used start a local cluster\n",
    "print(datetime.now())\n",
    "client='no_dask'\n",
    "if luse_dask :\n",
    "    \n",
    "    import dask.bag as db  \n",
    "    from dask.distributed import Client, LocalCluster\n",
    "\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=3,\n",
    "        )\n",
    "\n",
    "    client=Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the work (dask or non-dask processing)\n",
    "if luse_dask:\n",
    "    # bag definition\n",
    "    dbag=db.from_sequence(dat_lst, npartitions=len(dat_lst))\n",
    "    dbag_final=dbag.map(process_data)\n",
    "\n",
    "    # process data\n",
    "    tout_lst = dbag_final.compute()\n",
    "else:\n",
    "    tout_lst=[]\n",
    "    for tdat in dat_lst:\n",
    "\n",
    "        # process data\n",
    "        tout = process_data(tdat) \n",
    "\n",
    "        # add data to dataset\n",
    "        tout_lst.append(tout)\n",
    "\n",
    "print(datetime.now())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e51fa",
   "metadata": {},
   "source": [
    "### convert to teos10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide if we need to convert data (presence of specific variable name in ddat_lst)\n",
    "lbot=False; loce=False\n",
    "\n",
    "if (dsbt in ddat_lst) and (dsbs in ddat_lst) and (dbathy in ddat_lst):\n",
    "    lbot=True\n",
    "\n",
    "if (dthetao in ddat_lst) and (dso in ddat_lst):\n",
    "    loce=True\n",
    "    \n",
    "# retreive data\n",
    "for ddat in tout_lst[:]:\n",
    "    if ddat[1] == 'tob' :\n",
    "        ctob=ddat[0].values\n",
    "    if ddat[1] == 'sob' :\n",
    "        saob=ddat[0].values\n",
    "    if ddat[1] == 'thetao':\n",
    "        cto = ddat[0].values\n",
    "    if ddat[1] == 'so':\n",
    "        sao = ddat[0].values\n",
    "    if ddat[1] == 'deptho':\n",
    "        zbot = ddat[0].values\n",
    "\n",
    "# convert with teos 10\n",
    "if lbot:\n",
    "    print('    convert bottom data from eos10 to eos80')\n",
    "    spob,tp0ob=convert_from_TEOS10_to_EOS80(ctob,saob,zbot,lonISMIP6,latISMIP6)\n",
    "    \n",
    "    for ddat in tout_lst[:]:\n",
    "        if ddat[1] == 'tob' :\n",
    "            ddat[0].values = tp0ob\n",
    "        if ddat[1] == 'sob' :\n",
    "            ddat[0].values = spob\n",
    "    \n",
    "if loce:\n",
    "    print('    convert ocean data from eos10 to eos80')\n",
    "    z2d=np.ones(shape=lonISMIP6.shape)\n",
    "    for jk in range(len(zISMIP6[0:-1])):\n",
    "        z2d = zISMIP6[jk]\n",
    "        sao[jk,:,:],cto[jk,:,:]=convert_from_TEOS10_to_EOS80(cto[jk,:,:],sao[jk,:,:],z2d,lonISMIP6,latISMIP6)\n",
    "    \n",
    "    for ddat in tout_lst[:]:\n",
    "        if ddat[1] == 'thetao':\n",
    "            ddat[0].values = cto\n",
    "        if ddat[1] == 'so':\n",
    "            ddat[0].values = sao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7901b",
   "metadata": {},
   "source": [
    "### set missing value in data set and any other modifications (convention, units ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca80b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set right convention for some variables and compute min_val and max val\n",
    "for ddat in tout_lst[:]:\n",
    "    \n",
    "    # temporary array\n",
    "    zdat = np.ma.masked_invalid(ddat[0].values)\n",
    "    \n",
    "    # change convention if needed\n",
    "    if ddat[1] == 'deptho':\n",
    "        print('    change topography sign')\n",
    "        zdat = - zdat\n",
    "    if ddat[1] == 'depfli':\n",
    "        print('    change ice shelf draft sign')\n",
    "        zdat = - zdat\n",
    "    if ddat[1] == 'ficeshelf':\n",
    "        print('    change ice shelf melt sign')\n",
    "        zdat = - zdat\n",
    "    \n",
    "    # compute min max\n",
    "    ddat[0].attrs['valid_min']=np.min(zdat)\n",
    "    ddat[0].attrs['valid_max']=np.max(zdat)\n",
    "    \n",
    "    # fill data\n",
    "    ddat[0].values = zdat.filled(fill_value=-9999.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6cf10",
   "metadata": {},
   "source": [
    "### write netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9cc22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output\n",
    "print('write data ...')\n",
    "for tout in tout_lst:\n",
    "    cvarISMIP6=tout[1]\n",
    "    print('    add '+cvarISMIP6+' ...')\n",
    "    ds[cvarISMIP6]=tout[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write coordinates and attributes\n",
    "print('    write coordinates')\n",
    "ds['x']=xcoord\n",
    "ds['y']=ycoord\n",
    "\n",
    "print('    write coordinates')\n",
    "ds['crs'] = 'epsg:3031'\n",
    "ds['crs'].attrs = dprj['att']\n",
    "\n",
    "print('    write global att')\n",
    "ds.attrs = dgatt\n",
    "\n",
    "print('    write netcdf ...')\n",
    "ds.to_netcdf(cf_out)\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at structure\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('load NEMO coordinate ...')\n",
    "# ncid= nc.Dataset(cf_coord_NEMO,'r')\n",
    "# rlatfNEMO = ncid.variables['gphif'][:,:].squeeze()      # debug\n",
    "# rlonfNEMO = ncid.variables['glamf'][:,:].squeeze()      # debug\n",
    "# ncid.close()\n",
    "# print('')\n",
    "\n",
    "# print('convert wgs84 to Antarctic Polar Stereographic ...')\n",
    "# transformer_lltoxy=pyproj.Transformer.from_crs('epsg:4326','epsg:3031',always_xy=True)\n",
    "# xfNEMO,yfNEMO = transformer_lltoxy.transform(rlonfNEMO,rlatfNEMO)     # debug\n",
    "# print('')\n",
    "\n",
    "# plt.pcolormesh(x2dISMIP6-4000., y2dISMIP6-4000., toto, vmin=-2.5,vmax=2,edgecolors='crimson')\n",
    "# plt.pcolormesh(xfNEMO[0:370,0:-1],yfNEMO[0:370,0:-1],mask2dNEMO[1:370,1:-1]*np.nan,\n",
    "#                     shading='flat',edgecolors='grey')\n",
    "\n",
    "# plt.scatter(xNEMO,yNEMO,c=maskNEMO,marker='o')\n",
    "# plt.scatter(x2dISMIP6, y2dISMIP6,c=mask,marker='s')\n",
    "\n",
    "# plt.xlim([300000, 380000])\n",
    "# plt.ylim([-1.32e6, -1.25e6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEMO_to_ISMIP6",
   "language": "python",
   "name": "nemo_to_ismip6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
